#!/usr/bin/env python

import libdircmp
import time
import argparse
import enum
import sys
import json
import os
import cPickle as pickle
import hashlib

class TagValue(enum.Enum):
    none = 1
    allTrue = 2
    allFalse = 3
    conflict = 4

def hashFileId( fileId, ignoreModified ):
    if ignoreModified:
        return [hashlib.sha1( pickle.dumps( (fileId['isDir'], fileId['size']) ) ).hexdigest()]
    else:
        # +- 100 seconds
        timestamp = int(fileId['modified']/100.0)
        return [
            hashlib.sha1( pickle.dumps( (fileId['isDir'], fileId['size'], timestamp-1) ) ).hexdigest(),
            hashlib.sha1( pickle.dumps( (fileId['isDir'], fileId['size'], timestamp+0) ) ).hexdigest(),
            hashlib.sha1( pickle.dumps( (fileId['isDir'], fileId['size'], timestamp+1) ) ).hexdigest()
            ]

def getContentHash( fileId, contentHashes ):
    oriPath = fileId['path'] if not ('oriPath' in fileId) else fileId['oriPath']
    return contentHashes[oriPath]

def compareFiles( a, b, ignoreModified, compareContents, leftSources, rightSources, leftContentHashes, rightContentHashes ):
    if a['isDir'] != b['isDir']: return False
    if a['size'] != b['size']: return False
    if not ignoreModified:
        if abs( a['modified'] - b['modified'] ) > 2*60: return False
    assert not a['isDir'] and not b['isDir']
    if compareContents:
        libdircmp.hashFileContents( a, leftSources, leftContentHashes )
        libdircmp.hashFileContents( b, rightSources, rightContentHashes )
        if getContentHash( a, leftContentHashes ) != getContentHash( b, rightContentHashes ): return False
    return True

def haveSameItems( list1, list2, id = lambda x: x ):
    set1 = set()
    set2 = set()
    for child in list1:
        item = list1[child]
        set1.add( id( item ) )
    for child in list2:
        item = list2[child]
        set2.add( id( item ) )
    return not (set1 ^ set2)

def compareDirectories( a, b, ignoreModified, compareContents ):
    if a['size'] != b['size']:
        return False

    aChildren = a['children']
    bChildren = b['children']

    if not haveSameItems(
        aChildren,
        bChildren,
        lambda id: (id['isDir'], id['name'])
        ):
        return False

    for child in aChildren:
        aId = aChildren[child]
        bId = bChildren[child]
        if aId['isDir']:
            if not compareDirectories( aId, bId, ignoreModified ):
                return False
        else:
            if not compareFiles( aId, bId, ignoreModified, compareContents, [], [], {}, {} ):
                return False

    return True

def findDirectories( leftDirectory, rightDirectory, leftIndex, rightIndex, leftCommonRootLen, rightCommonRootLen, args ):
    print( 'searching directory partners...' )
    lastOutput = time.time()

    subjects = []
    for leftFile in leftDirectory:
        leftFileId = leftDirectory[leftFile]
        if leftFileId['isDir'] and leftFileId['children']:
            subjects.append( leftFileId )

    partners = []
    subjects = sorted( subjects, key = lambda s: s['name'].lower() )
    counter = 0
    for subject in subjects:
        for rightPath in rightIndex:
            if subject['path'] == rightPath:
                continue
            rightFileId = rightIndex[rightPath]
            if rightFileId['isDir']:
                if compareDirectories( subject, rightFileId, args.ignore_modified, args.contents ):
                    partners.append( (subject, rightFileId) )

        counter += 1
        if time.time() - lastOutput > 10:
            print( '%i/%i...' % (counter, len(subjects)) )
            lastOutput = time.time()

    printPartnersSimple( subjects, partners, leftCommonRootLen, rightCommonRootLen, args )

def findFiles( leftDirectory, rightDirectory, leftIndex, rightIndex, leftCommonRootLen, rightCommonRootLen, leftSources, rightSources, args ):
    leftContentHashes = {}
    rightContentHashes = {}
    if args.hashfile_left and os.path.isfile( args.hashfile_left ):
        print( 'loading subject hashes...' )
        leftContentHashes = json.load( open( args.hashfile_left, 'r' ) )
    if args.hashfile_right and os.path.isfile( args.hashfile_right ):
        print( 'loading target hashes...' )
        rightContentHashes = json.load( open( args.hashfile_right, 'r' ) )

    print( 'indexing targets...' )
    rightFileIdIndex = {}
    for rightPath in rightIndex:
        rightFileId = rightIndex[rightPath]
        targetHashes = hashFileId( rightFileId, args.ignore_modified )
        for targetHash in targetHashes:
            if not targetHash in rightFileIdIndex:
                rightFileIdIndex[targetHash] = []
            rightFileIdIndex[targetHash].append( rightFileId )

    print( 'searching file partners...' )
    lastOutput = time.time()
    lastSave = time.time()

    subjects = []
    for leftPath in leftIndex:
        leftFileId = leftIndex[leftPath]
        if not leftFileId['isDir']:
            subjects.append( leftFileId )

    partners = []
    subjects = sorted( subjects, key = lambda s: s['path'].lower() )
    counter = 0
    for subject in subjects:
        subjectHashes = hashFileId( subject, args.ignore_modified )
        subjectPartners = []
        for subjectHash in subjectHashes:
            if args.singles_only and subjectPartners: break
            if subjectHash in rightFileIdIndex:
                for potentialTarget in rightFileIdIndex[subjectHash]:
                    if subject['path'] == potentialTarget['path']:
                        continue
                    if compareFiles( subject, potentialTarget, args.ignore_modified, args.contents, leftSources, rightSources, leftContentHashes, rightContentHashes ):
                        if not potentialTarget in subjectPartners:
                            subjectPartners.append( potentialTarget )
                            if args.singles_only and subjectPartners: break
        if subjectPartners:
            partners.append( (subject, sorted( subjectPartners, key = lambda s: s['path'].lower() )) )

        counter += 1
        if time.time() - lastOutput > 10: # each 10 sec
            print( '%i/%i...' % (counter, len(subjects)) )
            lastOutput = time.time()

            if (args.hashfile_left or args.hashfile_right) and time.time() - lastSave > 60*30: # each 30 min
                assert args.contents
                print( 'saving hashes so far...' )
                if args.hashfile_left:
                    json.dump( leftContentHashes, open( args.hashfile_left, 'w' ), indent = 4 )
                if args.hashfile_right:
                    json.dump( rightContentHashes, open( args.hashfile_right, 'w' ), indent = 4 )
                lastSave = time.time()

    if args.hashfile_left or args.hashfile_right:
        assert args.contents
        print( 'saving hashes...' )
        if args.hashfile_left:
            json.dump( leftContentHashes, open( args.hashfile_left, 'w' ), indent = 4 )
        if args.hashfile_right:
            json.dump( rightContentHashes, open( args.hashfile_right, 'w' ), indent = 4 )

    printPartnersGroup( subjects, partners, leftDirectory, rightDirectory, leftIndex, rightIndex, leftCommonRootLen, rightCommonRootLen, args )

def printPartnersSimple( subjects, partners, leftCommonRootLen, rightCommonRootLen, args ):
    color_green = '\033[92m'
    color_red   = '\033[91m'
    color_blue = '\033[94m'
    color_end   = '\033[0m'

    print( '%i partners found.' % len( partners ) )
    if not args.singles_only:
        for partner in partners:
            print( '%s%s%s has partner %s%s%s' % (
                color_green, partner[0]['path'][leftCommonRootLen:], color_end,
                color_blue, partner[1]['path'][rightCommonRootLen:], color_end
                ) )

    if not args.partners_only:
        singles = []
        matchedSubjects = set( map( lambda x: x[0]['path'], partners ) )
        for subject in sorted( subjects, key = lambda s: s['name'].lower() ): # TODO: sort by name? why not by path?
            if not subject['path'] in matchedSubjects:
                singles.append( subject )
        print( '%i singles (without partners).' % len( singles ) )
        for single in singles:
            print( '%s%s%s has no partner' % (
                color_red, single['path'][leftCommonRootLen:], color_end,
                ) )

def markDirectoriesContainingTaggedFiles( directory, tag, directoryFileId = None ):
    tagValue = TagValue.none
    for filename in directory:
        fileId = directory[filename]
        if fileId['isDir']:
            markDirectoriesContainingTaggedFiles( fileId['children'], tag, fileId )
        if tagValue == TagValue.none:
            tagValue = fileId[tag]
        elif tagValue != fileId[tag]:
            tagValue = TagValue.conflict
    if directoryFileId:
        directoryFileId[tag] = tagValue

def appendTaggedItems( itemList, directory, tag ):
    for filename in directory:
        fileId = directory[filename]
        if fileId[tag] == TagValue.allTrue:
            itemList.append( fileId )
        else:
            if fileId['isDir']:
                appendTaggedItems( itemList, fileId['children'], tag )

def printPartnersGroup( subjects, partners, leftDirectory, rightDirectory, leftIndex, rightIndex, leftCommonRootLen, rightCommonRootLen, args ):
    color_green = '\033[92m'
    color_red   = '\033[91m'
    color_blue = '\033[94m'
    color_end   = '\033[0m'

    # as in printPartnersSimple
    print( '%i partners found.' % len( partners ) )
    if not args.singles_only:
        for partner in partners:
            targets = map( lambda x: x['path'][rightCommonRootLen:], partner[1] )
            print( '%s%s%s has partner(s) %s%s%s' % (
                color_green, partner[0]['path'][leftCommonRootLen:], color_end,
                color_blue, ("%s, %s" % (color_end, color_blue)).join( targets ), color_end
                ) )

    if not args.partners_only:
        singles = []
        matchedSubjects = set( map( lambda x: x[0]['path'], partners ) )
        for subject in subjects:
            if not subject['path'] in matchedSubjects:
                singles.append( subject )
        print( '%i singles (without partner).' % len( singles ) )
        # mark files
        for leftPath in leftIndex:
            leftFileId = leftIndex[leftPath]
            leftFileId['single'] = TagValue.none if leftFileId['isDir'] else TagValue.allFalse
        for single in singles:
            leftIndex[single['path']]['single'] = TagValue.allTrue
        # mark directories
        markDirectoriesContainingTaggedFiles( leftDirectory, 'single' )
        singles = []
        appendTaggedItems( singles, leftDirectory, 'single' )
        for single in singles:
            print( '%s%s%s (%s) has no partner' % (
                color_red,
                single['path'][leftCommonRootLen:] + ('/' if single['isDir'] else ''),
                color_end,
                libdircmp.formatBytes( single['size'] )
                ) )

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument( 'left', help = 'directory or json file' )
    parser.add_argument( 'right', help = 'directory or json file' )
    parser.add_argument( '--dirs', help = 'only search for top level directories' )
    parser.add_argument( '--ignore-modified', action = 'store_true' )
    parser.add_argument( '--partners-only', action = 'store_true' )
    parser.add_argument( '--singles-only', action = 'store_true' )
    parser.add_argument( '--only', action = 'append', help = 'include paths (exact match); only on directory scans' )
    parser.add_argument( '--skip', action = 'append', help = 'exclude paths (exact match); only on directory scans' )
    parser.add_argument( '--save-left', help = 'only on directory scans or content searches' )
    parser.add_argument( '--save-right', help = 'only on directory scans or content comparisons' )
    parser.add_argument( '--exclude', action = 'append', help = 'exclude paths (regex match)' )
    parser.add_argument( '--include', action = 'append', help = 'include paths only (regex match)' )
    parser.add_argument( '--rewrite-left', help = 'rewrite left root directory for comparison' )
    parser.add_argument( '--rewrite-right', help = 'rewrite right root directory for comparison' )
    parser.add_argument( '--contents', action = 'store_true', help = 'compare contents for potential matches' )
    parser.add_argument( '--source-left', action = 'append', help = 'left data source for hashing, may be old::new' )
    parser.add_argument( '--source-right', action = 'append', help = 'right data source for hashing, may be old::new' )
    parser.add_argument( '--hashfile-left', help = 'only for content comparisons' )
    parser.add_argument( '--hashfile-right', help = 'only for content comparisons' )
    args = parser.parse_args()

    if not args.contents and (args.source_left or args.source_right):
        print( "Error: --source-left and --source-right work only with --contents." )
        sys.exit( 1 )

    if not args.contents and (args.hashfile_left or args.hashfile_right):
        print( "Error: --hashfile-left and --hashfile-right work only with --contents." )
        sys.exit( 1 )

    if args.contents and args.dirs:
        print( "Error: --contents not supported in --dirs mode." )
        sys.exit( 1 )

    (leftDirectory, leftIndex, leftCommonRoot) = libdircmp.scan(
        args.left, args.rewrite_left, 'subjects', args.save_left, args
        )

    (rightDirectory, rightIndex, rightCommonRoot) = libdircmp.scan(
        args.right, args.rewrite_right, 'targets', args.save_right, args
        )

    leftSources = libdircmp.getSources( args.source_left, leftCommonRoot )
    rightSources = libdircmp.getSources( args.source_right, rightCommonRoot )

    if args.dirs:
        findDirectories( leftDirectory, rightDirectory, leftIndex, rightIndex, len(leftCommonRoot), len(rightCommonRoot), args )
    else:
        findFiles( leftDirectory, rightDirectory, leftIndex, rightIndex, len(leftCommonRoot), len(rightCommonRoot), leftSources, rightSources, args )

if __name__ == "__main__":
    main()